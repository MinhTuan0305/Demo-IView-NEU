# AI-Powered Interview Question Generator & Evaluation System

An intelligent system that generates personalized interview questions from CV files using Google Gemini AI and provides automated evaluation of candidate responses.

## ğŸš€ Features

- **CV Processing**: Supports both PDF and image formats (PNG, JPG, JPEG, BMP, TIFF)
- **Smart Question Generation**: Creates 9 tailored interview questions based on CV content and job requirements
- **Interactive Interview**: Conducts real-time interviews with candidates
- **AI-Powered Evaluation**: Automatically scores responses across multiple criteria
- **Multi-language Support**: Vietnamese and English interface support
- **Flexible Job Levels**: Supports Intern, Fresher, Junior, Senior, and Lead levels

## ğŸ“‹ System Overview

The system consists of three main components:

1. **Question Generator** (`generate_questions.py`) - Extracts CV content and generates interview questions
2. **Interactive Interview** (`ask.py`) - Conducts the actual interview session
3. **Response Evaluator** (`evaluate.py`) - Scores candidate responses using AI

## ğŸ› ï¸ Prerequisites

- **Python 3.9+**
- **Google Gemini API Key** - Get yours from [Google AI Studio](https://makersuite.google.com/app/apikey)
- **Tesseract OCR** - For text extraction from images and PDFs

## ğŸ”§ Setup

### 1. Clone and Install Dependencies

```bash
git clone <repository-url>
cd interview-ai-main
pip install -r requirements.txt
```

### 2. Configure Environment (Gemini + Supabase)

Create a `.env` file in the `backend/` directory with the following content:

```bash
# ==== Supabase ====
# Get from Supabase â†’ Project Settings â†’ API
SUPABASE_URL=https://YOUR_PROJECT_REF.supabase.co
# Prefer SERVICE_ROLE_KEY for server-side only (never expose to client)
SUPABASE_SERVICE_ROLE_KEY=YOUR_SERVICE_ROLE_KEY
# Optional (for testing if not using service role)
# SUPABASE_ANON_KEY=YOUR_ANON_KEY

# ==== Gemini API ====
GEMINI_API_KEY=your_actual_gemini_api_key_here
```

**âš ï¸ Security Note:** Never commit the `.env` file to version control. It's already included in `.gitignore`.

### Installing Tesseract OCR

**Windows:**
```bash
# Download from: https://github.com/UB-Mannheim/tesseract/wiki
# Or use chocolatey:
choco install tesseract
```

**macOS:**
```bash
brew install tesseract
```

**Linux (Ubuntu/Debian):**
```bash
sudo apt-get install tesseract-ocr
```

## ğŸ“¦ Installation

1. **Clone the repository:**
```bash
git clone <repository-url>
cd Generate_questions_Altered
```

2. **Install dependencies:**
```bash
pip install -r requirements.txt
```

3. **Optional: Install PDF processing dependencies:**
```bash
# For enhanced PDF processing
pip install pdf2image
# Install poppler for pdf2image
# macOS: brew install poppler
# Ubuntu: sudo apt-get install poppler-utils
```

2. **Place CV files:**
Put your CV files (PDF or images) in the `CV/` directory.

## ğŸ¯ Usage

### Step 1: Generate Interview Questions

Generate personalized interview questions from CV files:

```bash
# Basic usage
python generate_questions.py --job "Data Scientist" --level "Senior"

# With custom directories
python generate_questions.py --job "Software Engineer" --level "Junior" --cv_dir CV --out interview_question

# Interactive mode (if parameters not provided)
python generate_questions.py
```

**Parameters:**
- `--job`: Target job position (e.g., "Data Scientist", "Software Engineer")
- `--level`: Candidate level ("Intern", "Fresher", "Junior", "Senior", "Lead")
- `--cv_dir`: Directory containing CV files (default: "CV")
- `--out`: Output directory for generated questions (default: "interview_question")

**Output:** JSON file with 9 structured interview questions in `interview_question/` directory.

### Step 2: Conduct Interactive Interview

Run the interview session with generated questions:

```bash
python ask.py
```

The script will:
- Automatically find the latest generated questions file
- Prompt for candidate name
- Present each question sequentially
- Record responses with timestamps
- Save results to `outputs/interview_logs/`

### Step 3: Evaluate Responses

Score candidate responses using AI evaluation:

```bash
# Cháº¥m Ä‘iá»ƒm táº¥t cáº£ file phá»ng váº¥n trong interview_logs
cd src/interview
python evaluate.py

```

**Features:**
- âœ¨ **Tá»± Ä‘á»™ng xá»­ lÃ½ táº¥t cáº£ file**: Script sáº½ tá»± Ä‘á»™ng tÃ¬m vÃ  cháº¥m Ä‘iá»ƒm táº¥t cáº£ file JSON trong `outputs/interview_logs/`
- ğŸ” **ThÃ´ng bÃ¡o tiáº¿n trÃ¬nh**: Hiá»ƒn thá»‹ danh sÃ¡ch file Ä‘Æ°á»£c tÃ¬m tháº¥y vÃ  tiáº¿n trÃ¬nh xá»­ lÃ½
- ğŸ›¡ï¸ **Xá»­ lÃ½ lá»—i**: Tiáº¿p tá»¥c xá»­ lÃ½ file khÃ¡c náº¿u má»™t file gáº·p lá»—i
- ğŸ“Š **Káº¿t quáº£ riÃªng biá»‡t**: Má»—i file phá»ng váº¥n sáº½ cÃ³ file káº¿t quáº£ cháº¥m Ä‘iá»ƒm riÃªng
- ğŸ¯ **ÄÃ¡nh giÃ¡ tá»•ng thá»ƒ**: AI phÃ¢n tÃ­ch toÃ n bá»™ cuá»™c phá»ng váº¥n Ä‘á»ƒ Ä‘Æ°a ra Ä‘Ã¡nh giÃ¡ tá»•ng thá»ƒ, Ä‘iá»ƒm máº¡nh, Ä‘iá»ƒm cáº§n cáº£i thiá»‡n vÃ  khuyáº¿n nghá»‹ tuyá»ƒn dá»¥ng

**Evaluation Criteria:**
- **Correctness**: Accuracy compared to expected key points
- **Coverage**: How many key points were addressed
- **Reasoning**: Logical explanation and argumentation
- **Creativity**: Examples and unique expressions
- **Communication**: Clarity and coherence
- **Attitude**: Positive or negative attitude

**Output:** Detailed scoring results saved to `outputs/evaluate_results/`

**Káº¿t quáº£ bao gá»“m:**
- **Äiá»ƒm tá»«ng cÃ¢u há»i**: Chi tiáº¿t Ä‘iá»ƒm sá»‘ cho tá»«ng cÃ¢u tráº£ lá»i
- **Äiá»ƒm trung bÃ¬nh**: Äiá»ƒm trung bÃ¬nh cá»§a toÃ n bá»™ cuá»™c phá»ng váº¥n
- **ÄÃ¡nh giÃ¡ tá»•ng thá»ƒ**: PhÃ¢n tÃ­ch AI vá» Ä‘iá»ƒm máº¡nh, Ä‘iá»ƒm cáº§n cáº£i thiá»‡n
- **Khuyáº¿n nghá»‹ tuyá»ƒn dá»¥ng**: Gá»£i Ã½ vá» viá»‡c cÃ³ nÃªn tuyá»ƒn dá»¥ng á»©ng viÃªn hay khÃ´ng

## ğŸ“ Project Structure

```
Generate_questions_Altered/
â”œâ”€â”€ CV/                          # Input CV files
â”œâ”€â”€ CV máº«u/                      # Sample CV images
â”œâ”€â”€ interview_question/          # Generated interview questions
â”‚   â””â”€â”€ *.questions.json        # Question files
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ interview_logs/         # Interview session recordings
â”‚   â””â”€â”€ evaluate_results/      # AI evaluation results
â”œâ”€â”€ generate_questions.py       # Question generation script
â”œâ”€â”€ ask.py                      # Interactive interview script
â”œâ”€â”€ evaluate.py                 # Response evaluation script
â”œâ”€â”€ requirements.txt            # Python dependencies
â””â”€â”€ README.md                   # This file
```

## ğŸ”§ Technical Details

### Question Generation Process

1. **Text Extraction**: 
   - PDFs: Uses `pypdf` for text extraction, falls back to OCR if needed
   - Images: Uses Tesseract OCR for text recognition
   - Fallback: Direct image analysis with Gemini Vision API

2. **Question Structure**:
   - **Questions 1-3**: Opening questions (self-introduction, strengths/weaknesses, motivation)
   - **Questions 4-5**: Behavioral questions (teamwork, challenges, motivation)
   - **Questions 6-8**: Technical questions (tailored to job and seniority level)
   - **Questions 9-10**: CV-based questions (specific project experience)
   - **Question 11**: Creative/hypothetical scenario

3. **AI Models**: Uses Google Gemini 2.5 Flash for both text and vision processing

### Supported File Formats

- **Images**: PNG, JPG, JPEG, BMP, TIFF, TIF
- **Documents**: PDF

### Output Formats

- **Questions**: JSON format with structured question data
- **Interviews**: JSON format with timestamps and responses
- **Evaluations**: JSON format with detailed scoring breakdown

## ğŸš¨ Troubleshooting

### Common Issues

1. **"Missing GEMINI_API_KEY"**
   - Ensure your `.env` file contains a valid API key
   - Check that the key has proper permissions

2. **"TesseractNotFoundError"**
   - Install Tesseract OCR following the platform-specific instructions
   - Ensure Tesseract is in your system PATH

3. **"No supported CV files found"**
   - Check that CV files are in the correct directory
   - Verify file extensions are supported

4. **"Model did not return valid JSON"**
   - The AI response will be saved as `.raw.txt` for inspection
   - Try running the generation again

### Performance Tips

- For large PDFs, consider using `pdf2image` for better OCR results
- Ensure good image quality for better text extraction
- Use specific job titles and levels for more targeted questions

## ğŸ“Š Example Output

### Generated Questions Structure
```json
[
  {
    "id": 1,
    "question": "HÃ£y giá»›i thiá»‡u báº£n thÃ¢n vÃ  trÃ¬nh bÃ y vá» kinh nghiá»‡m lÃ m viá»‡c cá»§a báº¡n.",
    "category": "opening",
    "purpose": "ÄÃ¡nh giÃ¡ kháº£ nÄƒng trÃ¬nh bÃ y vÃ  tá»± tin"
  },
  {
    "id": 2,
    "question": "Khi lÃ m viá»‡c vá»›i Data Science á»Ÿ cáº¥p Senior, báº¡n sáº½ thiáº¿t káº¿ má»™t há»‡ thá»‘ng ML pipeline nhÆ° tháº¿ nÃ o Ä‘á»ƒ Ä‘áº£m báº£o scalability vÃ  maintainability?",
    "category": "technical",
    "purpose": "ÄÃ¡nh giÃ¡ kiáº¿n thá»©c ká»¹ thuáº­t vÃ  kháº£ nÄƒng thiáº¿t káº¿ há»‡ thá»‘ng",
    "focus": "ML pipeline design"
  }
]
```

### Evaluation Results Structure
```json
{
  "summary": {
    "candidate_name": "John Doe",
    "interview_date": "2024-01-15 14:30:00",
    "average_overall_score": 78.5,
    "questions_scored": 9
  },
  "details": {
    "1": {
      "correctness": 8,
      "coverage": 7,
      "reasoning": 6,
      "creativity": 5,
      "communication": 9,
      "attitude": 10,
      "overall_score": 75,
      "feedback": "á»¨ng viÃªn trÃ¬nh bÃ y rÃµ rÃ ng nhÆ°ng cáº§n cáº£i thiá»‡n pháº§n vÃ­ dá»¥ cá»¥ thá»ƒ..."
    }
  }
}
```

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Test thoroughly
5. Submit a pull request

## ğŸ“„ License

This project is licensed under the MIT License - see the LICENSE file for details.

## ğŸ™ Acknowledgments

- Google Gemini AI for powerful language processing
- Tesseract OCR for text extraction capabilities
- The open-source community for various Python libraries

---

**Note**: This system is designed for educational and assessment purposes. Always ensure compliance with data privacy regulations when processing candidate information.